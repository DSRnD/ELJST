{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import operator\n",
    "import nltk\n",
    "import os, glob\n",
    "import string\n",
    "import copy\n",
    "import copy\n",
    "import pickle\n",
    "import datetime\n",
    "import joblib, multiprocessing\n",
    "import utils as my_utils\n",
    "\n",
    "from scipy import spatial\n",
    "from collections import Counter\n",
    "from scipy.special import gammaln\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 5\n",
    "max_df = .5\n",
    "max_features = 50000\n",
    "\n",
    "n_cores = -1\n",
    "max_iter = 20\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = glob.glob(\"datasets/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['datasets/amazon_home_20000_dataset',\n",
    "            'datasets/amazon_movies_20000_dataset',\n",
    "            'datasets/amazon_kindle_20000_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_score(list):\n",
    "\n",
    "    all_words = []\n",
    "\n",
    "    for l in list:\n",
    "\n",
    "        all_words += l\n",
    "\n",
    "    temp = pd.DataFrame(all_words,columns=['a'])\n",
    "\n",
    "    temp = temp['a'].value_counts().reset_index()\n",
    "\n",
    "    temp.columns = ['word','tot_cnt']\n",
    "\n",
    "    return temp[temp.tot_cnt == 1].shape[0]*1.0/temp.tot_cnt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/amazon_home_20000_dataset 5\n",
      "0.20484953318416485 -0.020598524253569072 13.213320272658683 -99.66533497403358 -2118173.6413778164 1217.2113232629647 0.05230238564676634 0.4\n",
      "datasets/amazon_home_20000_dataset 25\n",
      "0.4448792067092359 -0.06102645032803739 8.890327700798919 -129.04242225088126 -2180171.5796270506 1498.5567124619836 -0.11774748525356267 0.608\n",
      "datasets/amazon_home_20000_dataset 50\n",
      "0.5561192673727636 -0.07108510957448319 8.057126309116065 -137.42937467547853 -2248558.3669411303 1884.8920547315863 -0.042144197892468184 0.67\n",
      "datasets/amazon_movies_20000_dataset 5\n",
      "0.28134043896046335 -0.048343009603952256 12.715371224276112 -97.3411599641646 -2186702.9600289147 1769.92860387285 0.1894072164698331 0.48\n",
      "datasets/amazon_movies_20000_dataset 25\n",
      "0.4445355196115952 -0.062207597201462544 11.715722724418477 -120.31474874711526 -2263327.001538447 2300.207648165319 0.17000349835660133 0.468\n",
      "datasets/amazon_movies_20000_dataset 50\n",
      "0.5257447102773432 -0.07681291471320877 10.9459869821858 -134.17093287832841 -2333958.191301683 2928.7144500325294 0.1397150850396454 0.552\n",
      "datasets/amazon_kindle_20000_dataset 5\n",
      "0.2185108734286543 -0.03319612361960598 10.801110401246813 -87.55363437246221 -1953601.519277994 1215.4178926507348 0.2605341154274313 0.36\n",
      "datasets/amazon_kindle_20000_dataset 25\n",
      "0.4515958935333063 -0.07322682772393774 11.080024452386892 -113.39781874193233 -2030174.6115681878 1605.5879505860323 0.35779888908440777 0.452\n",
      "datasets/amazon_kindle_20000_dataset 50\n",
      "0.5350725446853694 -0.06637790431213718 10.038166964283038 -132.5941682060347 -2099997.97460727 2069.592258261475 -0.2278056565193382 0.61\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    for n_topics in [5, 25, 50]:\n",
    "        print(d, n_topics)\n",
    "\n",
    "        dataset = pd.read_pickle(d)\n",
    "        vectorizer = CountVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,\n",
    "                                     stop_words=\"english\", max_features=max_features,\n",
    "                                     max_df=max_df, min_df=min_df)\n",
    "\n",
    "        count_matrix = vectorizer.fit_transform(dataset.text.tolist()).toarray()\n",
    "        words = vectorizer.get_feature_names()\n",
    "\n",
    "        vocabulary = dict(zip(words,np.arange(len(words))))\n",
    "\n",
    "        model = LatentDirichletAllocation(n_components=n_topics, max_iter=max_iter, n_jobs=n_cores, verbose=0)\n",
    "\n",
    "        dt_distribution = model.fit_transform(count_matrix)\n",
    "\n",
    "        topic_words = {}\n",
    "        for topic, comp in enumerate(model.components_):\n",
    "            word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "            topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "        sample_df = []\n",
    "        for topic, word in topic_words.items():\n",
    "            sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "\n",
    "        print(my_utils.get_hscore_multi(dt_distribution, count_matrix, n_topics, 2000), \n",
    "              silhouette_score(count_matrix, dt_distribution.argmax(axis=1)),\n",
    "              davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)),\n",
    "              my_utils.coherence_score(count_matrix, sample_df, vocabulary),\n",
    "              model.score(count_matrix),\n",
    "              model.perplexity(count_matrix),\n",
    "              my_utils.coherence_score2(count_matrix, sample_df, vocabulary),\n",
    "              get_diversity_score(sample_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"datasets/amazon_electronics_20000_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,\n",
    "                             stop_words=\"english\", max_features=max_features,\n",
    "                             max_df=max_df, min_df=min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = vectorizer.fit_transform(dataset.text.tolist()).toarray()\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict(zip(words,np.arange(len(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentDirichletAllocation(n_components=n_topics, max_iter=20, n_jobs=n_cores, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = {}\n",
    "for topic, comp in enumerate(model.components_):\n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "    topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "sample_df = []\n",
    "for topic, word in topic_words.items():\n",
    "    sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "dt_distribution = model.transform(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_utils.get_hscore_multi(dt_distribution, count_matrix, n_topics, 2000), \n",
    "      silhouette_score(count_matrix, dt_distribution.argmax(axis=1)),\n",
    "      davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)),\n",
    "      my_utils.coherence_score(count_matrix, sample_df, vocabulary),\n",
    "      model.score(count_matrix),\n",
    "      model.perplexity(count_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"H Score:\", my_utils.get_hscore_multi(dt_distribution, count_matrix, n_topics, 2000))\n",
    "# print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "# print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "# print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "# print(\"Log Likelihood:\", model.score(count_matrix))\n",
    "# print(\"Perplexity:\", model.perplexity(count_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     print(\"\\nK:\", k)\n",
    "#     print(\"Running Metrics...\")\n",
    "#     print(\"H Score:\", my_utils.get_hscore_multi(dt_distribution, count_matrix, k, 3000))\n",
    "#     print(\"Log Likelihood:\", model.score(count_matrix))\n",
    "#     print(\"Perplexity:\", model.perplexity(count_matrix))\n",
    "#     print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "#     print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "#     print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "    \n",
    "# #     print my_utils.coherence_score(count_matrix, sample_df, vocabulary), \"\\t\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)), \"\\t\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_evaluations_multi(model):\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     h_score =  my_utils.get_hscore_multi(dt_distribution, count_matrix, k)\n",
    "#     likelihood =  model.score(count_matrix)\n",
    "#     perplexity = model.perplexity(count_matrix)\n",
    "#     coherance_score = my_utils.coherence_score(count_matrix, sample_df, vocabulary)\n",
    "#     silhouette = silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     return [h_score, likelihood, perplexity, coherance_score, silhouette]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     print(\"\\nK:\", k)\n",
    "#     print(\"Running Metrics...\")\n",
    "#     print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "#     print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "#     print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"H-Score:\", my_utils.get_hscore(dt_distribution, count_matrix, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_distribution)\n",
    "\n",
    "# X_embedded.shape\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_distribution.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
