{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy import spatial\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import imp, multiprocessing\n",
    "import LDA_ETM as lda\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import utils as my_utils\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"dumps/mrf_lda/amazon_*50*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_score(list):\n",
    "\n",
    "    all_words = []\n",
    "\n",
    "    for l in list:\n",
    "\n",
    "        all_words += l\n",
    "\n",
    "    temp = pd.DataFrame(all_words,columns=['a'])\n",
    "\n",
    "    temp = temp['a'].value_counts().reset_index()\n",
    "\n",
    "    temp.columns = ['word','tot_cnt']\n",
    "\n",
    "    return temp[temp.tot_cnt == 1].shape[0]*1.0/temp.tot_cnt.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = glob.glob(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dumps/mrf_lda/amazon_movies_20000_glove_0.6_50topics',\n",
       " 'dumps/mrf_lda/amazon_kindle_20000_glove_0.6_50topics',\n",
       " 'dumps/mrf_lda/amazon_home_20000_glove_0.6_50topics']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(sampler):\n",
    "\n",
    "    dt_distribution = sampler.theta()\n",
    "\n",
    "    ss = silhouette_score(euclidean_distances(sampler.matrix),\n",
    "                          dt_distribution.argmax(axis=1), metric='precomputed')\n",
    "\n",
    "    dbs = davies_bouldin_score(sampler.matrix, dt_distribution.argmax(axis=1))\n",
    "\n",
    "    chs = my_utils.coherence_score(sampler.matrix, list(sampler.getTopKWords(10, sampler.words).values()), sampler.vocabulary)\n",
    "\n",
    "    hsc = my_utils.get_hscore_multi(dt_distribution, sampler.matrix, sampler.n_topics, 2000)\n",
    "\n",
    "    loli = sampler.loglikelihood()\n",
    "\n",
    "    pxy = sampler.perplexity()\n",
    "    \n",
    "    chs2 = my_utils.coherence_score2(sampler.matrix, list(sampler.getTopKWords(10, sampler.words).values()), sampler.vocabulary)\n",
    "    \n",
    "    div = get_diversity_score(list(sampler.getTopKWords(10, sampler.words).values()))\n",
    "    \n",
    "    print(str(hsc) + \",\" + str(ss) + \",\" + str(dbs) + \",\" + str(chs) + \",\" + str(loli) + \",\" + str(pxy) + \",\" + str(chs2) + \",\" + str(div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumps/mrf_lda/amazon_movies_20000_glove_0.6_50topics\n",
      "0.5642029984429587,-0.06483622893014271,13.29183169074436,-127.09362795162397,-2942715.439212765,23489.67089741538,-4.098540749223562,1.0\n",
      "dumps/mrf_lda/amazon_kindle_20000_glove_0.6_50topics\n",
      "0.5385896604449018,-0.06754959973552477,13.438293758180837,-121.97279233113937,-2681931.3187743444,17169.364207770508,-3.9041531942018093,1.0\n",
      "dumps/mrf_lda/amazon_home_20000_glove_0.6_50topics\n",
      "0.5178474109116609,-0.06789467762060722,10.248945935040362,-128.8824496045749,-2875711.7365965103,15445.722398864924,-2.764778231742038,1.0\n"
     ]
    }
   ],
   "source": [
    "for i in dumps:\n",
    "    print(i)\n",
    "    get_scores(sampler = joblib.load(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = joblib.load(dumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = list(sampler.getTopKWords(10, sampler.words).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 500})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(Counter(np.array(top_words).reshape(-1)).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_dist = sampler.theta()\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_dist)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_dist.argmax(axis=1))\n",
    "# plt.legend(loc=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print \"\"\n",
    "#     print \"Topics:\", k\n",
    "#     print \"Coherance:\", my_utils.coherence_score(count_matrix, top_words, vocabulary)\n",
    "#     print \"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     print \"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_new",
   "language": "python",
   "name": "python3_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
